# NEURAL-NETWORK-TECHNIQUE-FOR-DETECTING-FACIAL-EXPRESSIONS-OF-EMOTION
Emotion Recognition is a task to process a human facial expression and classify 
it into certain emotion categories. Such task typically requires the feature 
extractor to detect the feature, and the trained classifier produces the label based 
on the feature. The problem is that the extraction of feature may be distorted by 
variance of location of object and lighting condition in the image. In this project, 
we address the solution of the problem by using a deep learning algorithm called 
Conventional Neural Network (CNN) to address the issues above. By using this 
algorithm, the feature of image can be extracted without user-defined featureengineering, and classifier model is integrated with feature extractor to produce 
the result when input is given. In this way, such method produces a featurelocation-invariant image classifier that achieves higher accuracy than traditional 
linear classifier when the variance such as lighting noise and background 
environment appears in the input image. The evaluation of the model shows that 
the accuracy of our lab condition testing data set is 84.63%, and for wild emotion 
detection it achieves only around 37% accuracy.
Keywords: Computer vision, Deep Learning, Convolution Neural Network
